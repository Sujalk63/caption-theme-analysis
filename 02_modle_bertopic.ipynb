{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d6f634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import regex as re \n",
    "import pandas as pd \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import PunktSentenceTokenizer, word_tokenize\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4074b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\Sujal Karmakar\\Desktop\\Desktop\\MyCareer\\Data World\\Data Analyst\\Python\\python_data_analytics_project\\Theme Finder Using Caption (NLP)\\Data\\reviews_of_orders_during_crisis.xlsx\"\n",
    "\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4673a4",
   "metadata": {},
   "source": [
    "#### 1) Basic Cleaning (lower case, remover numbers, emoji, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5b6d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_caption = df[[\"order_id\", \"review\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b5473a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          order_id               review      review_cleaned\n",
      "0  ORD202504000898  Not worth the price     not worth price\n",
      "1  ORD202504020679  Not worth the price     not worth price\n",
      "2  ORD202506000002  Not worth the price     not worth price\n",
      "3  ORD202506000005   Average experience  average experience\n",
      "4  ORD202506000006            Bad taste           bad taste\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# list of generic words and hashtags that i wanna remove\n",
    "generic_words = set(\n",
    "    [\n",
    "        \"the\",\n",
    "        \"and\",\n",
    "        \"to\",\n",
    "        \"of\",\n",
    "        \"in\",\n",
    "        \"for\",\n",
    "        \"this\",\n",
    "        \"is\",\n",
    "        \"you\",\n",
    "        \"our\",\n",
    "        \"by\",\n",
    "        \"foundmademodern\",\n",
    "        \"link\",\n",
    "        \"bio\",\n",
    "        \"we\",\n",
    "        \"my\",\n",
    "        \"from\",\n",
    "        \"with\",\n",
    "        \"was\",\n",
    "        \"at\",\n",
    "        \"followfriday\",\n",
    "        \"please\",\n",
    "        \"love\",\n",
    "        \"follow\",\n",
    "        \"introduce\",\n",
    "        \"your\",\n",
    "        \"on\",\n",
    "        \"is\",\n",
    "        \"that\",\n",
    "        \"are\",\n",
    "        \"all\",\n",
    "        \"out\",\n",
    "        \"more\",\n",
    "        \"handmade\",\n",
    "        \"it\", \n",
    "        \"art\", \n",
    "        \"diy\", \n",
    "        \"make\", \n",
    "        \"so\", \n",
    "        \"craftsposure\", \n",
    "        \"craft\", \n",
    "        \"be\", \n",
    "        \"shop\", \n",
    "        \"have\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def clean_caption(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).strip()\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    text_lower = re.sub(r\"#(\\w+)\", r\"\\1\", text_lower)\n",
    "\n",
    "    text_lower = re.sub(r\"\\s+\", \" \", text_lower)\n",
    "\n",
    "    for phrase in generic_words:\n",
    "        # Add word boundaries \\b to avoid partial matches\n",
    "        pattern = r\"\\b\" + re.escape(phrase) + r\"\\b\"\n",
    "        text_lower = re.sub(pattern, \"\", text_lower, flags=re.IGNORECASE)\n",
    "\n",
    "    text_lower = re.sub(r\"\\s+\", \" \", text_lower).strip()\n",
    "\n",
    "    return text_lower\n",
    "\n",
    "\n",
    "df_caption_cleaned = df[[\"order_id\", \"review\"]].copy()\n",
    "\n",
    "df_caption_cleaned[\"review_cleaned\"] = df_caption_cleaned[\"review\"].apply(\n",
    "    clean_caption\n",
    ")\n",
    "\n",
    "print(df_caption_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b59a61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>review</th>\n",
       "      <th>review_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4794</th>\n",
       "      <td>ORD202507007526</td>\n",
       "      <td>Cold food</td>\n",
       "      <td>cold food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5254</th>\n",
       "      <td>ORD202507009373</td>\n",
       "      <td>Stale food served</td>\n",
       "      <td>stale food served</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9417</th>\n",
       "      <td>ORD202509002663</td>\n",
       "      <td>Portion size smaller than expected</td>\n",
       "      <td>portion size smaller than expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11575</th>\n",
       "      <td>ORD202509009365</td>\n",
       "      <td>Cold food</td>\n",
       "      <td>cold food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9949</th>\n",
       "      <td>ORD202509004264</td>\n",
       "      <td>Bad taste</td>\n",
       "      <td>bad taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>ORD202506010466</td>\n",
       "      <td>Packaging was poor</td>\n",
       "      <td>packaging poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11442</th>\n",
       "      <td>ORD202509008968</td>\n",
       "      <td>Food safety issue</td>\n",
       "      <td>food safety issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10599</th>\n",
       "      <td>ORD202509006285</td>\n",
       "      <td>Packaging was poor</td>\n",
       "      <td>packaging poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10970</th>\n",
       "      <td>ORD202509007452</td>\n",
       "      <td>Cold food</td>\n",
       "      <td>cold food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6260</th>\n",
       "      <td>ORD202508002496</td>\n",
       "      <td>Packaging was poor</td>\n",
       "      <td>packaging poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>ORD202506010012</td>\n",
       "      <td>Food quality is not good</td>\n",
       "      <td>food quality not good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>ORD202506001228</td>\n",
       "      <td>Cold food</td>\n",
       "      <td>cold food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>ORD202506004058</td>\n",
       "      <td>Stale food served</td>\n",
       "      <td>stale food served</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10946</th>\n",
       "      <td>ORD202509007372</td>\n",
       "      <td>Very late</td>\n",
       "      <td>very late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8031</th>\n",
       "      <td>ORD202508008649</td>\n",
       "      <td>Food quality is not good</td>\n",
       "      <td>food quality not good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              order_id                              review  \\\n",
       "4794   ORD202507007526                           Cold food   \n",
       "5254   ORD202507009373                   Stale food served   \n",
       "9417   ORD202509002663  Portion size smaller than expected   \n",
       "11575  ORD202509009365                           Cold food   \n",
       "9949   ORD202509004264                           Bad taste   \n",
       "2983   ORD202506010466                  Packaging was poor   \n",
       "11442  ORD202509008968                   Food safety issue   \n",
       "10599  ORD202509006285                  Packaging was poor   \n",
       "10970  ORD202509007452                           Cold food   \n",
       "6260   ORD202508002496                  Packaging was poor   \n",
       "2858   ORD202506010012            Food quality is not good   \n",
       "365    ORD202506001228                           Cold food   \n",
       "1120   ORD202506004058                   Stale food served   \n",
       "10946  ORD202509007372                           Very late   \n",
       "8031   ORD202508008649            Food quality is not good   \n",
       "\n",
       "                           review_cleaned  \n",
       "4794                            cold food  \n",
       "5254                    stale food served  \n",
       "9417   portion size smaller than expected  \n",
       "11575                           cold food  \n",
       "9949                            bad taste  \n",
       "2983                       packaging poor  \n",
       "11442                   food safety issue  \n",
       "10599                      packaging poor  \n",
       "10970                           cold food  \n",
       "6260                       packaging poor  \n",
       "2858                food quality not good  \n",
       "365                             cold food  \n",
       "1120                    stale food served  \n",
       "10946                           very late  \n",
       "8031                food quality not good  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_caption_cleaned.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd25b2",
   "metadata": {},
   "source": [
    "#### 2) Tokenization (removing stop words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e6e2767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "\n",
    "# # Define a custom download directory\n",
    "# custom_nltk_path = r'C:\\Users\\Sujal Karmakar\\.conda\\envs\\DS\\nltk_data'\n",
    "\n",
    "# # Download resources to the custom path\n",
    "## nltk.download('punkt', download_dir=custom_nltk_path)\n",
    "# nltk.download('punkt_tab', download_dir=custom_nltk_path)\n",
    "# nltk.download('stopwords', download_dir=custom_nltk_path)\n",
    "\n",
    "# # Manually add the path to NLTK's search locations\n",
    "# nltk.data.path.append(custom_nltk_path)\n",
    "\n",
    "# i had to explicitly download these by specifying files and also punkt was not working for me nltk was demanding punkt_tab so i did that \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70213a3f",
   "metadata": {},
   "source": [
    "#### 3) Creating dictionaries and corpus for LDA (Linear discriminant analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54a7289a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 13:42:12,793 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2d5f36778b402ca8148f414aa27c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/372 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 13:42:23,885 - BERTopic - Embedding - Completed ✓\n",
      "2025-11-09 13:42:23,886 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-11-09 13:42:26,052 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-11-09 13:42:26,053 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-11-09 13:42:26,498 - BERTopic - Cluster - Completed ✓\n",
      "2025-11-09 13:42:26,499 - BERTopic - Representation - Extracting topics using c-TF-IDF for topic reduction.\n",
      "2025-11-09 13:42:26,551 - BERTopic - Representation - Completed ✓\n",
      "2025-11-09 13:42:26,552 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2025-11-09 13:42:26,593 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2025-11-09 13:42:26,620 - BERTopic - Representation - Completed ✓\n",
      "2025-11-09 13:42:26,623 - BERTopic - Topic reduction - Reduced number of topics from 86 to 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Topic  Count                         Name  \\\n",
      "0      -1    494     -1_good_quality_not_food   \n",
      "1       0   1080      0_good_quality_not_food   \n",
      "2       1   1076         1_safety_issue_food_   \n",
      "3       2    997          2_packaging_issue__   \n",
      "4       3    972                3_taste_bad__   \n",
      "5       4    971         4_served_stale_food_   \n",
      "6       5    942          5_recommended_not__   \n",
      "7       6    904                6_very_late__   \n",
      "8       7    668                7_cold_food__   \n",
      "9       8    658  8_than_smaller_size_portion   \n",
      "10      9    657           9_price_worth_not_   \n",
      "11     10    645      10_experience_average__   \n",
      "12     11    630          11_poor_packaging__   \n",
      "13     12    630    12_great_quality_not_food   \n",
      "14     13    156             13_worst_order__   \n",
      "15     14    133             14_never_again__   \n",
      "16     15    131        15_terrible_hygiene__   \n",
      "17     16    127        16_service_horrible__   \n",
      "18     17     11     17_good_quality_not_food   \n",
      "19     18     11     18_good_quality_not_food   \n",
      "\n",
      "                                       Representation  \\\n",
      "0              [good, quality, not, food, , , , , , ]   \n",
      "1              [good, quality, not, food, , , , , , ]   \n",
      "2                 [safety, issue, food, , , , , , , ]   \n",
      "3                  [packaging, issue, , , , , , , , ]   \n",
      "4                        [taste, bad, , , , , , , , ]   \n",
      "5                 [served, stale, food, , , , , , , ]   \n",
      "6                  [recommended, not, , , , , , , , ]   \n",
      "7                        [very, late, , , , , , , , ]   \n",
      "8                        [cold, food, , , , , , , , ]   \n",
      "9   [than, smaller, size, portion, expected, , , ,...   \n",
      "10                  [price, worth, not, , , , , , , ]   \n",
      "11              [experience, average, , , , , , , , ]   \n",
      "12                  [poor, packaging, , , , , , , , ]   \n",
      "13            [great, quality, not, food, , , , , , ]   \n",
      "14                     [worst, order, , , , , , , , ]   \n",
      "15                     [never, again, , , , , , , , ]   \n",
      "16                [terrible, hygiene, , , , , , , , ]   \n",
      "17                [service, horrible, , , , , , , , ]   \n",
      "18             [good, quality, not, food, , , , , , ]   \n",
      "19             [good, quality, not, food, , , , , , ]   \n",
      "\n",
      "                                  Representative_Docs  \n",
      "0   [food quality not good, food quality not good,...  \n",
      "1   [food quality not good, food quality not good,...  \n",
      "2   [food safety issue, food safety issue, food sa...  \n",
      "3   [packaging issue, packaging issue, packaging i...  \n",
      "4                   [bad taste, bad taste, bad taste]  \n",
      "5   [stale food served, stale food served, stale f...  \n",
      "6   [not recommended, not recommended, not recomme...  \n",
      "7                   [very late, very late, very late]  \n",
      "8                   [cold food, cold food, cold food]  \n",
      "9   [portion size smaller than expected, portion s...  \n",
      "10  [not worth price, not worth price, not worth p...  \n",
      "11  [average experience, average experience, avera...  \n",
      "12   [packaging poor, packaging poor, packaging poor]  \n",
      "13  [food quality not great, food quality not grea...  \n",
      "14            [worst order, worst order, worst order]  \n",
      "15            [never again, never again, never again]  \n",
      "16  [terrible hygiene, terrible hygiene, terrible ...  \n",
      "17  [horrible service, horrible service, horrible ...  \n",
      "18  [food quality not good, food quality not good,...  \n",
      "19  [food quality not good, food quality not good,...  \n",
      "\n",
      "Topic 0:\n",
      "[('good', 0.1770953562829483), ('quality', 0.13832665468553948), ('not', 0.08943003728884767), ('food', 0.0718446110226399), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 1:\n",
      "[('safety', 0.30924966602050546), ('issue', 0.1947296852818699), ('food', 0.0957928146968532), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 2:\n",
      "[('packaging', 0.3493317952517999), ('issue', 0.2920945279228049), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 3:\n",
      "[('taste', 0.4952140490348534), ('bad', 0.4952140490348534), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 4:\n",
      "[('served', 0.33035841476192146), ('stale', 0.33035841476192146), ('food', 0.0957928146968532), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 5:\n",
      "[('recommended', 0.5051244538048331), ('not', 0.17886007457769534), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 6:\n",
      "[('very', 0.5183135219919695), ('late', 0.5183135219919695), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 7:\n",
      "[('cold', 0.6210062443473967), ('food', 0.1436892220452798), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 8:\n",
      "[('than', 0.2505525936990736), ('smaller', 0.2505525936990736), ('size', 0.2505525936990736), ('portion', 0.2505525936990736), ('expected', 0.2505525936990736), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 9:\n",
      "[('price', 0.4179498569324058), ('worth', 0.4179498569324058), ('not', 0.11924004971846355), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 10:\n",
      "[('experience', 0.6335283898762565), ('average', 0.6335283898762565), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 11:\n",
      "[('poor', 0.6420077559997363), ('packaging', 0.3493317952517999), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 12:\n",
      "[('great', 0.3210038779998681), ('quality', 0.13832665468553948), ('not', 0.08943003728884767), ('food', 0.0718446110226399), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 13:\n",
      "[('worst', 1.2231206689632095), ('order', 1.2231206689632095), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 14:\n",
      "[('never', 1.296447643926048), ('again', 1.296447643926048), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 15:\n",
      "[('terrible', 1.303460800175482), ('hygiene', 1.303460800175482), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 16:\n",
      "[('service', 1.3178385223532174), ('horrible', 1.3178385223532174), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 17:\n",
      "[('good', 0.1770953562829483), ('quality', 0.13832665468553948), ('not', 0.08943003728884767), ('food', 0.0718446110226399), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n",
      "\n",
      "Topic 18:\n",
      "[('good', 0.1770953562829483), ('quality', 0.13832665468553948), ('not', 0.08943003728884767), ('food', 0.0718446110226399), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05), ('', 1e-05)]\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "documents = df_caption_cleaned[\"review_cleaned\"].tolist()\n",
    "\n",
    "topic_model = BERTopic(language=\"english\", nr_topics=20, verbose=True)\n",
    "\n",
    "topics, probs = topic_model.fit_transform(documents)\n",
    "\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(topic_info)\n",
    "\n",
    "\n",
    "for topic_num in topic_info[\"Topic\"]:\n",
    "    if topic_num != -1:  # -1 is the noise topic\n",
    "        print(f\"\\nTopic {topic_num}:\")\n",
    "        print(topic_model.get_topic(topic_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db538520",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bertopic_topics_2.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for idx, topic in topic_model.get_topic_info().iterrows():\n",
    "        f.write(f\"Topic {topic['Topic']} (Count: {topic['Count']}):\\n\")\n",
    "        terms = topic_model.get_topic(topic[\"Topic\"])\n",
    "        for term, weight in terms:\n",
    "            f.write(f\"  {term}: {weight:.4f}\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2683da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping topic IDs to clear, professional names\n",
    "\n",
    "# topic_labels = {\n",
    "#     -1: \"Bad Packaging\",\n",
    "#     0: \"Quality(Stale/Cold/Hygiene)\",\n",
    "#     1: \"Quality(Stale/Cold/Hygiene)\",\n",
    "#     2: \"Bad Taste\",\n",
    "#     3: \"Bad Service\",\n",
    "#     4: \"Delivery Delay\",\n",
    "#     5: \"Bad Packaging\",\n",
    "#     6: \"Quality(Stale/Cold/Hygiene)\",\n",
    "#     7: \"Smaller Quantity\",\n",
    "#     8: \"High Price\",\n",
    "#     9: \"Bad Service\",\n",
    "#     10: \"Bad Packaging\",\n",
    "#     11: \"Quality(Stale/Cold/Hygiene)\",\n",
    "#     12: \"Quality(Stale/Cold/Hygiene)\",\n",
    "#     13: \"Bad Service\",\n",
    "#     14: \"Bad Service\",\n",
    "#     15: \"Quality(Stale/Cold/Hygiene)\",\n",
    "#     16: \"Bad Service\",\n",
    "#     17: \"Quality(Stale/Cold/Hygiene)\",\n",
    "#     18: \"Quality(Stale/Cold/Hygiene)\",\n",
    "# }\n",
    "topic_labels = {\n",
    "    -1: \"Quality(Stale/Cold/Hygiene)\",\n",
    "    0: \"Quality(Stale/Cold/Hygiene)\",\n",
    "    1: \"Quality(Stale/Cold/Hygiene)\",\n",
    "    2: \"Bad Packaging\",\n",
    "    3: \"Bad Taste\",\n",
    "    4: \"Quality(Stale/Cold/Hygiene)\",\n",
    "    5: \"Bad Service\",\n",
    "    6: \"Delivery Delay\",\n",
    "    7: \"Quality(Stale/Cold/Hygiene)\",\n",
    "    8: \"Smaller Quantity\",\n",
    "    9: \"High Price\",\n",
    "    10: \"Bad Service\",\n",
    "    11: \"Bad Packaging\",\n",
    "    12: \"Quality(Stale/Cold/Hygiene)\",\n",
    "    13: \"Bad Service\",\n",
    "    14: \"Bad Service\",\n",
    "    15: \"Quality(Stale/Cold/Hygiene)\",\n",
    "    16: \"Bad Service\",\n",
    "    17: \"Quality(Stale/Cold/Hygiene)\",\n",
    "    18: \"Quality(Stale/Cold/Hygiene)\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93e366bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          order_id               review  Topic_ID   Topic_Name\n",
      "0  ORD202504000898  Not worth the price         9   High Price\n",
      "1  ORD202504020679  Not worth the price         9   High Price\n",
      "2  ORD202506000002  Not worth the price         9   High Price\n",
      "3  ORD202506000005   Average experience        10  Bad Service\n",
      "4  ORD202506000006            Bad taste         3    Bad Taste\n"
     ]
    }
   ],
   "source": [
    "df_topics = pd.DataFrame(\n",
    "    {\"order_id\": df_caption_cleaned[\"order_id\"], \"Topic_ID\": topics}\n",
    ")\n",
    "\n",
    "df_topics[\"Topic_Name\"] = df_topics[\"Topic_ID\"].map(topic_labels)\n",
    "\n",
    "df_final = df.merge(df_topics, on=\"order_id\", how=\"left\")\n",
    "\n",
    "print(df_final.head())\n",
    "\n",
    "\n",
    "df_final.to_excel(\"quick_bite_bad_reviews_with_topics.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
